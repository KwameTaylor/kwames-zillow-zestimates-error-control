{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kwame's Zillow Zestimates Error Control\n",
    "\n",
    "Table of contents with header links goes here.\n",
    "\n",
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'model_1_test' from 'model' (/Users/a666/codeup-data-science/kwames-zillow-zestimates-error-control/model.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-db1037a0a94a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mzillow_main_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzillow_Xy_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpute_nulls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzillow_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misolation_forest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_RFE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexplore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mviz_logerror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr_heatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttest_viz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mttest_hypo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_is_1960s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_1960s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_heatmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbath_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_log_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprop_val_log_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounty_log_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_k\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_cluster_area\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_area_viz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoose_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintertia_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_area_dummies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_1_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# default viz size settings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'model_1_test' from 'model' (/Users/a666/codeup-data-science/kwames-zillow-zestimates-error-control/model.py)"
     ]
    }
   ],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import necessary packages/modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, TweedieRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from wrangle import get_zillow_data, prepare_zillow\n",
    "from preprocessing import zillow_main_split, zillow_Xy_split, impute_nulls, zillow_scale, isolation_forest, concat_dfs, my_RFE\n",
    "from explore import viz_logerror, corr_heatmap, ttest_viz, ttest_hypo, make_is_1960s, map_1960s, error_heatmap, bath_plot, cluster_log_plot, prop_val_log_plot, county_log_plot, map_k\n",
    "from model import create_cluster_area, cluster_area_viz, choose_k, intertia_k, cluster_area_dummies, model_1, model_2, model_3, model_1_test\n",
    "\n",
    "# default viz size settings\n",
    "plt.rc('figure', figsize=(9, 7))\n",
    "plt.rc('font', size=13)\n",
    "\n",
    "# default pandas decimal number display format\n",
    "#pd.options.display.float_format = '{:20,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "---\n",
    "\n",
    "## Acquire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquire the zillow data\n",
    "df = get_zillow_data()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "****\n",
    "\n",
    "## Prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_zillow(df)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize the clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining nulls have to be imputed after the data split so that we aren't cheating with our data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train, validate, test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main split\n",
    "train, validate, test = zillow_main_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shape of train data: {train.shape}')\n",
    "print(f'Shape of validate data: {validate.shape}')\n",
    "print(f'Shape of test data: {test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute the remaining nulls with medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = impute_nulls(train)\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = impute_nulls(validate)\n",
    "validate.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = impute_nulls(test)\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_logerror(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There are outliers present on both ends.**\n",
    "\n",
    "**Now that I'm on my second iteration through the data science pipeline, I will handle these outliers using an Isolation Forest that detects anomalies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Current shape of train:', train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Isolation Forest, or iForest for short, is a tree-based anomaly detection algorithm.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporarily split data into X and y\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = zillow_Xy_split(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolation Forest\n",
    "X_train, X_validate, X_test, y_train, y_validate, y_test = isolation_forest(X_train, X_validate, X_test, y_train, y_validate, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat the dfs back together\n",
    "train = concat_dfs(train, X_train, y_train)\n",
    "validate = concat_dfs(validate, X_validate, y_validate)\n",
    "test = concat_dfs(test, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making sure my iForest didn't drop too much data\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now I'll visualize the distribution of log error again to check that the outliers were removed successfully.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_logerror(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looks good, so let's move on to scaling the data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler, train_scaled, validate_scaled, test_scaled = zillow_scale(train, validate, test)\n",
    "train_scaled.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "---\n",
    "\n",
    "## Explore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data and create visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those unfamiliar with the data, here is a simple correlation heatmap for a quick glance at the features' relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_heatmap(train_scaled.drop(columns=['logerror']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It would be interesting to explore the correlation between year built and the number of bathrooms, but in the interest of time I will come back to that in the future, because right now my target is log error.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(train.decade)\n",
    "plt.title('Distribution of decade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_heatmap(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Counties:** Los Angeles = 0, Orange = 1, Ventura = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways at this point in the pipeline before I handled outliers:**\n",
    "* Looks like properties built in the 1800s and early 1900s have slightly more log error, especially in Ventura county. Granted, there are not very many properties that meet those criteria, so let's do a statisical test to find out if it's significant or not.\n",
    "* There seems to be slightly more log error in Orange county.\n",
    "\n",
    "**Takeaways after I handled outliers:**\n",
    "* After I handled the outliers, it got rid of all the properties built before 1907.\n",
    "* Now I see that there is actually less log error in the early 1900s, I am adding a new hypothesis test regarding year built and getting rid of the old one (\"There is a difference in Zestimate log error in properties built in the 1800s and the overall log error\"), which is no longer applicable.\n",
    "* I also noticed that my Isolation Forest dropped all Ventura county properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.century.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My iForest also dropped the 2,000 or so properties that were built in the 2000s.**\n",
    "\n",
    "****\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-sample, 2-tailed T-test:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is there a significant difference in the log error of Zestimates on properties built in the 1960s and the overall log error?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\begin{align*}\n",
    "   H_0 & : \\text{There is no difference in Zestimate log error in properties built in the 1960s and the overall log error.}\n",
    "   \\\\\n",
    "   H_a & : \\text{There is a difference in Zestimate log error in properties built in the 1960s and the overall log error.}\n",
    "   \\\\\n",
    "    \\alpha & : \\text{0.05}\n",
    "\\end{align*}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.decade.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_viz(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will say that the mean and median are close enough for this iteration, but I could try to improve this in future iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now that we know the variable has a normal distribution and we compared the mean and median, we can run the T-test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_hypo(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaways from first iteration t-test:\n",
    "\n",
    "**There doesn't seem to be a statistically significant difference in log error in properties built in the 1800s and the overall log error.**\n",
    "\n",
    "**However I do notice that the distribution of the log error of properties built in the 1800s is skewed differently (left) from the overall log error.**\n",
    "\n",
    "Takeaways from second iteration t-test:\n",
    "\n",
    "**It looks like there IS a significant difference in log error in properties built in the 1960s (versus the overall mean)! I'll make this into a feature.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering with Explore findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to add the new feature is_1960s to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = make_is_1960s(train)\n",
    "validate = make_is_1960s(validate)\n",
    "test = make_is_1960s(test)\n",
    "train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = make_is_1960s(train_scaled)\n",
    "validate_scaled = make_is_1960s(validate_scaled)\n",
    "test_scaled = make_is_1960s(test_scaled)\n",
    "train_scaled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_1960s(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bath_plot(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less log error on properties with half baths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_val_log_plot(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there is definitely more error amongst lower value properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_log_plot(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More log error in Los Angeles county."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "## Feature Engineering with Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['latitude', 'longitude', 'county']]\n",
    "Xv = validate_scaled[['latitude', 'longitude', 'county']]\n",
    "Xt = test_scaled[['latitude', 'longitude', 'county']]\n",
    "kmeans, centroids = create_cluster_area(train, train_scaled, validate, validate_scaled, test, test_scaled, X, Xv, Xt, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby('cluster_area').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.groupby('cluster_area').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=train_scaled.drop(columns=['latitude', 'longitude', 'century', 'decade', 'bathcnt', 'logerror']), hue='cluster_area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline iteration 2 Takeaway: **These clusters don't look super useful in distinguishing groups of like properties as of now.**\n",
    "\n",
    "Pipeline iteration 3 Takeaway: **These clusters could be useful to seperate properties with similar values and year built.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intertia_k(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Judging by the elbow method, the sweet spot for my k-value should be around 4 or 5. I'll look closer with a visualization.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_k(X, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I actually really like the region clusters for ```k = 6```, so I'm going to use ```k = 6``` to re-create my new feature (cluster_area) to use in modeling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['cluster_area'])\n",
    "train_scaled = train_scaled.drop(columns=['cluster_area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled[['latitude', 'longitude', 'county']]\n",
    "Xv = validate_scaled[['latitude', 'longitude', 'county']]\n",
    "Xt = test_scaled[['latitude', 'longitude', 'county']]\n",
    "kmeans, centroids = create_cluster_area(train, train_scaled, validate, validate_scaled, test, test_scaled, X, Xv, Xt, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I'll run pairplot on the re-created cluster feature\n",
    "sns.pairplot(data=train_scaled.drop(columns=['latitude', 'longitude', 'century', 'decade', 'bathcnt', 'logerror', 'is_1960s']), hue='cluster_area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline iteration 2 takeaway: **Looks like cluster 0, which only has Los Angeles county properties, has the highest values of all the area clusters in: property value, bathbed count, and square feet. I'll visualize that area in a future pipeline iteration.**\n",
    "\n",
    "Pipeline iteration 3 takeaway: **There is still a lot of overlap, but it looks like these clusters have somewhat useful distinctions in property values, year built, square feet, and a little in bathbedcnt.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_log_plot(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focus on reducing log error in clusters with a bigger range in log error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time to get dummies for the area cluster to make it better to model with.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = cluster_area_dummies(train)\n",
    "validate = cluster_area_dummies(validate)\n",
    "test = cluster_area_dummies(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = cluster_area_dummies(train_scaled)\n",
    "validate_scaled = cluster_area_dummies(validate_scaled)\n",
    "test_scaled = cluster_area_dummies(test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check to make sure my area cluster dummies function is still working\n",
    "validate_scaled.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The goal is to produce a predictive model that outperforms the baseline in predicting the target value -- in this case, the log error in the Zestimate of a single-unit property from 2017.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Features to use in Modeling with RFE (Recursive Feature Elimination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFE feature reduction\n",
    "X = train_scaled.drop(columns=['logerror'])\n",
    "k = 8\n",
    "\n",
    "my_RFE(X, k, train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipeline iteration 1:**\n",
    "\n",
    "Based on my RFE results, I will use bathbedcnt, century and cluster_area as predicter features.\n",
    "\n",
    "I won't use bathcnt or county because the feature redundancy from overlap could overfit my model by effectively giving more weight to some features.\n",
    "\n",
    "**Pipeline iteration 2:**\n",
    "\n",
    "Based on my RFE results, I will use bathcnt, sqft, latitude, and yearbuilt as predicter features.\n",
    "\n",
    "**Pipeline iteration 3:**\n",
    "\n",
    "Based on my RFE results, I will use (in order of importance): value, yearbuilt, bathbedcnt, cluster_area_5, and cluster_area_1 as predicter features.\n",
    "\n",
    "I was going to use sqft, but it has a strong correlation with bathbedcnt, so it would be redundant.\n",
    "\n",
    "The same goes for why I'm dropping latitude in favor of cluster_area_1 and cluster_area_5, and decade for yearbuilt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Evaluate Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(train.logerror)\n",
    "#np.median(train.logerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipeline iteration 1 & 2: **I'm going to go with the median as a baseline prediction for log error since I still have some outliers present in my data.**\n",
    "\n",
    "Pipeline iteration 3: **I'm going to go with the mean because, according to calculations, it makes a better performing baseline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = train.logerror.mean()\n",
    "\n",
    "baseline_rmse_train = round(mean_squared_error(train.logerror, np.full(len(train.logerror), baseline))**1/2, 6)\n",
    "print('RMSE (Root Mean Square Error) of Baseline on train data:\\n', baseline_rmse_train)\n",
    "baseline_rmse_validate = round(mean_squared_error(validate.logerror, np.full(len(validate.logerror), baseline))**1/2, 6)\n",
    "print('RMSE (Root Mean Square Error) of Baseline on validate data:\\n', baseline_rmse_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Models, Evaluate Models, and Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 - Ordinary Least Squares (OLS) using Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value, yearbuilt, bathbedcnt, cluster_area_5, and cluster_area_1\n",
    "\n",
    "X = train_scaled.drop(columns=['logerror', 'bathcnt', 'sqft', 'latitude', 'longitude', 'county', 'decade', 'century', 'is_1960s', 'cluster_area_2', 'cluster_area_3', 'cluster_area_4'])\n",
    "y = train_scaled.logerror\n",
    "\n",
    "X_v = validate_scaled.drop(columns=['logerror', 'bathcnt', 'sqft', 'latitude', 'longitude', 'county', 'decade', 'century', 'is_1960s', 'cluster_area_2', 'cluster_area_3', 'cluster_area_4'])\n",
    "y_v = validate_scaled.logerror\n",
    "\n",
    "lm_pred, lm_rmse, lm_pred_v, lm_rmse_v = model_1(X, y, X_v, y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model performs better than the baseline. Yay!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 - Lasso & Lars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_scaled.drop(columns=['logerror'])\n",
    "y = train_scaled.logerror\n",
    "\n",
    "X_v = validate_scaled.drop(columns=['logerror'])\n",
    "y_v = validate_scaled.logerror\n",
    "\n",
    "pred_lars, rmse_train, pred_lars_v, rmse_validate = model_2(X, y, X_v, y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model performs better than baseline, and almost the same as Model 1, but very slightly less accurate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try using all features with OLS\n",
    "\n",
    "X = train_scaled.drop(columns=['logerror'])\n",
    "y = train_scaled.logerror\n",
    "\n",
    "X_v = validate_scaled.drop(columns=['logerror'])\n",
    "y_v = validate_scaled.logerror\n",
    "\n",
    "lm_pred, lm_rmse, lm_pred_v, lm_rmse_v = model_3(X, y, X_v, y_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model is obviously overfit, probably because some features are redundant.**\n",
    "\n",
    "**Now that I know Model 1 is the best performing, I will test it on the test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value, yearbuilt, bathbedcnt, cluster_area_5, and cluster_area_1\n",
    "\n",
    "X = train_scaled.drop(columns=['logerror', 'bathcnt', 'sqft', 'latitude', 'longitude', 'county', 'decade', 'century', 'is_1960s', 'cluster_area_2', 'cluster_area_3', 'cluster_area_4'])\n",
    "y = train_scaled.logerror\n",
    "\n",
    "X_v = validate_scaled.drop(columns=['logerror', 'bathcnt', 'sqft', 'latitude', 'longitude', 'county', 'decade', 'century', 'is_1960s', 'cluster_area_2', 'cluster_area_3', 'cluster_area_4'])\n",
    "y_v = validate_scaled.logerror\n",
    "\n",
    "lm_pred, lm_rmse = model_1_test(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Conclusion and Takeaways - How to prevent future error in Zestimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
